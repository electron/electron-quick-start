<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Retrieve Headers from URLs</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for curlGetHeaders {base}"><tr><td>curlGetHeaders {base}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>
Retrieve Headers from URLs
</h2>

<h3>Description</h3>

<p>Retrieve the headers for a URL for a supported protocol such as
<code>http://</code>, <code>ftp://</code>, <code>https://</code> and <code>ftps://</code>.
An optional function not supported on all platforms.
</p>


<h3>Usage</h3>

<pre>
curlGetHeaders(url, redirect = TRUE, verify = TRUE)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>url</code></td>
<td>
<p>character string specifying the URL.</p>
</td></tr>
<tr valign="top"><td><code>redirect</code></td>
<td>
<p>logical: should redirections be followed?</p>
</td></tr>
<tr valign="top"><td><code>verify</code></td>
<td>
<p>logical: should certificates be verified as valid
and applying to that host?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This reports what <code>curl -I -L</code> or <code>curl -I</code> would
report.  For a <code>ftp://</code> URL the &lsquo;headers&rsquo; are a record of
the conversation between client and server before data transfer.
</p>
<p>Only 500 header lines will be reported: there is a limit of 20
redirections so this should suffice (and even 20 would indicate
problems).
</p>
<p>It uses <code><a href="options.html">getOption</a>("timeout")</code> for the connection
timeout: that defaults to 60 seconds.  As this cannot be interrupted
you may want to consider a shorter value.
</p>
<p>To see all the details of the interaction with the server(s) set
<code><a href="options.html">options</a>(internet.info = 1)</code>.
</p>
<p>HTTP[S] servers are allowed to refuse requests to read the headers and
some do: this will result in a <code>status</code> of <code>405</code>.
</p>
<p>For possible issues with secure URLs (especially on Windows) see
<code><a href="../../utils/html/download.file.html">download.file</a></code>.
</p>
<p>There is a security risk in not verifying certificates, but as only
the headers are captured it is slight.  Usually looking at the URL in
a browser will reveal what the problem is (and it may well be
machine-specific).
</p>


<h3>Value</h3>

<p>A character vector with integer attribute <code>"status"</code> (the
last-received &lsquo;status&rsquo; code).  If redirection occurs this will include
the headers for all the URLs visited.
</p>
<p>For the interpretation of &lsquo;status&rsquo; codes see
<a href="https://en.wikipedia.org/wiki/List_of_HTTP_status_codes">https://en.wikipedia.org/wiki/List_of_HTTP_status_codes</a> and
<a href="https://en.wikipedia.org/wiki/List_of_FTP_server_return_codes">https://en.wikipedia.org/wiki/List_of_FTP_server_return_codes</a>.
A successful FTP connection will usually have status 250 or 350.  
</p>


<h3>See Also</h3>

<p><code><a href="capabilities.html">capabilities</a>("libcurl")</code> to see if this is supported.
</p>
<p><code><a href="options.html">options</a></code> <code>HTTPUserAgent</code> and <code>timeout</code> are used.
</p>


<h3>Examples</h3>

<pre>## needs Internet access, results vary
curlGetHeaders("http://bugs.r-project.org")   ## this redirects to https://
curlGetHeaders("https://httpbin.org/status/404")  ## returns status
curlGetHeaders("ftp://cran.r-project.org")

## Not run:  ## a not-always-available site:
curlGetHeaders("ftps://test.rebex.net/readme.txt")

## End(Not run)</pre>

<hr /><div style="text-align: center;">[Package <em>base</em> version 3.6.1 <a href="00Index.html">Index</a>]</div>
</body></html>
